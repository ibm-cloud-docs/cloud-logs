---

copyright:
  years:  2024
lastupdated: "2024-07-17"

keywords:

subcollection: cloud-logs

---

{{site.data.keyword.attribute-definition-list}}



# Migrating {{site.data.keyword.la_full_notm}} instances
{: #migration-la}

Migrating {{site.data.keyword.la_full}} instances to {{site.data.keyword.logs_full_notm}} in {{site.data.keyword.cloud_notm}} require the configuration of the {{site.data.keyword.logs_routing_full_notm}} agent in the account and provisioning {{site.data.keyword.logs_full_notm}} instances. A migration tool is provided to help you migrate.
{: shortdesc}



## {{site.data.keyword.la_full_notm}} architecture
{: #migration-platform-la-ov}


You can use {{site.data.keyword.la_full_notm}} instances to monitor application logs, operational logs, and platform logs in the {{site.data.keyword.cloud_notm}} and outside the {{site.data.keyword.cloud_notm}}.

- Scenario 1:  {{site.data.keyword.la_full_notm}} instances that collect platform logs only:

    To monitor platform logs, you might have configured an {{site.data.keyword.la_full_notm}} instance for each region where you operate and where logs are generated by enabled services and the {{site.data.keyword.cloud_notm}} platform. To migrate these instances, see [Migrating instances that collect platform logs](/docs/cloud-logs?topic=cloud-logs-migration-platform-logs).

- Scenario 2: {{site.data.keyword.la_full_notm}} instances that collect service, application and operational logs:

    You can send logs to the {{site.data.keyword.la_full_notm}} instance through different methods depending on the source such as configuring the LogDNA agent or using the ingestion REST API and libraries to send application logs.

- Scenario 3: {{site.data.keyword.la_full_notm}} instances that collect all types of logs such as service, application and operational logs, and platform logs.



## Migration steps for instances that collect service, application and operational logs
{: #migration-la-steps-scenario2}


To migrate {{site.data.keyword.la_full_notm}} instances that collect operational and application logs,
- You must provision {{site.data.keyword.logs_full_notm}} instances in the account to replace the existing {{site.data.keyword.la_full_notm}} instances.

- You must also configure your data sources to send data to these {{site.data.keyword.logs_full_notm}} instances.

    You can configure an {{site.data.keyword.logs_routing_full_notm}} agent on supported platforms such as Kubernetes clusters, Red Hat OpenShift clusters, and Linux servers, or send data directly to {{site.data.keyword.logs_full_notm}} by using the ingestion endpoint. Sources sending logs can be in {{site.data.keyword.cloud_notm}}, on-prem, or running in another cloud service.

The Migration tool migrates instances replicating the current account architecture.

To migrate {{site.data.keyword.la_full_notm}} instances, complete the following steps for each instance:

1. Run the migration tool to collect information about what instances need to be migrated and their resources.

    ```text
    ibmcloud logging migrate generate-terraform --scope account --service logdna
    ```
    {: pre}


2. Migrate an instance by running one of these commands:

    * To generate terraform scripts that you can modify, run:

       ```text
       ibmcloud logging migrate create-resources --scope instance --instance-crn CRNvalue --terraform
       ```
       {: pre}

    * To migrate an instance by applying Terraform, run:

       ```text
       ibmcloud logging migrate create-resources --scope instance --instance-crn CRNvalue --terraform -f
       ```
       {: pre}

    * To migrate an instance directly without Terraform, run:

       ```text
       ibmcloud logging migrate create-resources --scope instance --instance-crn CRNvalue --api
       ```
       {: pre}

    You must migrate all your {{site.data.keyword.la_full_notm}} instances that collect platform logs before you use the Migration tool to configure {{site.data.keyword.logs_routing_full_notm}} in the account.{: important}

3. Manually configure notification channels such as email, and PagerDuty.

    If you use the terraform option, variables are provided for you to enter information on the slack URL and the webhook header apikey.

   {{site.data.keyword.logs_full_notm}} alerting is done by using the {{site.data.keyword.en_full_notm}} service.
   {: note}

4. Configure the {{site.data.keyword.logs_routing_full_notm}} agent to send logs.

    - [Managing the IBM速 Cloud Logs Routing agent for Linux](/docs/logs-router?topic=logs-router-agent-linux&interface=api).
    - [Managing the IBM速 Cloud Logs Routing agent for IBM Cloud Kubernetes Service clusters](/docs/logs-router?topic=logs-router-agent-std-cluster&interface=api).
    - [Managing the IBM速 Cloud Logs Routing agent for Red Hat OpenShift on IBM Cloud clusters](/docs/logs-router?topic=logs-router-agent-openshift&interface=api).
    - [Configuring the IBM速 Cloud Logs Routing agent for (r)Syslog logs](/docs/logs-router?topic=logs-router-agent-rsyslog&interface=api).

5. Validate that the new configuration is working for your requirements.

6. After you validate your configuration is operating as required, delete your {{site.data.keyword.la_full_notm}} instances and your legacy configurations to send data.



## Migration steps for instances that collect all types of logs
{: #migration-la-steps-scenario3}


To migrate {{site.data.keyword.la_full_notm}} instances that collect all logs,
- You must provision {{site.data.keyword.logs_full_notm}} instances in the account to replace the existing {{site.data.keyword.la_full_notm}} instances.

- You must also configure your data sources to send data to these {{site.data.keyword.logs_full_notm}} instances.

    You can configure an {{site.data.keyword.logs_routing_full_notm}} agent on supported platforms such as Kubernetes clusters, Red Hat OpenShift clusters, and Linux servers, or send data directly to {{site.data.keyword.logs_full_notm}} by using the ingestion endpoint. Sources sending logs can be in {{site.data.keyword.cloud_notm}}, on-prem, or running in another cloud service.

- You must configure {{site.data.keyword.logs_routing_full_notm}} to route platform logs to the {{site.data.keyword.logs_full_notm}} instance that you choose.

The Migration tool migrates instances replicating the current account architecture.

To migrate {{site.data.keyword.la_full_notm}} instances, complete the following steps for each instance:

- Complete the steps for instances that collect service, application and operational logs.
- Complete the steps for [Migrating instances that collect platform logs](/docs/cloud-logs?topic=cloud-logs-migration-platform-logs).

## Validating the new architecture
{: #migration-la-options-validate}

While you migrate and validate the new architecture, you must send logs to your {{site.data.keyword.la_full_notm}} instances, same as you currently do now. You must also send logs in parallel to your {{site.data.keyword.logs_full_notm}} instances to replicate your current architecture in the account.

Until you have validated the new architecture and you can remove the {{site.data.keyword.la_full_notm}} instances from the account, you must continue managing data through the deprecated services.
{: important}



## Checklist to plan for migration
{: #migration-la-checklist}

Consider these items when you are planning your migration of {{site.data.keyword.la_full_notm}} instances in an account:

- [ ] Identify the regions where you operate and where {{site.data.keyword.la_full_notm}} instances are provisioned.

- [ ] Identify the {{site.data.keyword.la_full_notm}} instances in regions where your [platform logs are configured to be collected](/docs/log-analysis?topic=log-analysis-config_svc_logs&interface=ui).

- [ ] Check your requirements for long-term storage. Do you have [archiving](/docs/log-analysis?topic=log-analysis-archiving-ov) configured for each {{site.data.keyword.la_full_notm}} instance? How long do you keep the data?

    In {{site.data.keyword.logs_full_notm}}, you can query all data that is stored in your configured {{site.data.keyword.cos_full_notm}} bucket. You own and maintain the bucket and the data stored in it.
    {: note}

- [ ] Are you streaming any data to other 3rd-party tools?

    The data format of logs does not change as part of the deprecation of the {{site.data.keyword.la_full_notm}} service.
    {: important}

- [ ] Are you [excluding any data at ingestion](/docs/log-analysis?topic=log-analysis-exclusion_rules) to reduce costs? Would it be useful to keep these logs for search or even for compliance? The {{site.data.keyword.logs_full_notm}} service offers a TCO feature to help you optimize costs based on data criticality and operational requirements. Take time to identify useful logs that you might be currently dropping due to cost constraints.

- [ ] Are you controlling data usage by configuring [index rate alerts](/docs/log-analysis?topic=log-analysis-control_usage_index_rate)?

- [ ] Do you [control access](/docs/log-analysis?topic=log-analysis-iam) by using access groups? Do you use trusted profiles or service IDs? [Identify the policies](/docs/log-analysis?topic=log-analysis-iam#iam_accesspolicy) in the account that grant permissions to operate the {{site.data.keyword.la_full_notm}} instances in the account.

- [ ] What [notification channels](/docs/log-analysis?topic=log-analysis-alerts#alerts_channels) do you use for alerting? Email, slack, PagerDuty, webhook, {{site.data.keyword.mon_full_notm}} (Sysdig).

- [ ] Make an inventory of the different types of sources of infrastructure and application logs that you are monitoring. What are your sources of the data? Do you collect logs from Kubernetes clusters, Red Hat OpenShift clusters, bare servers and so on?
